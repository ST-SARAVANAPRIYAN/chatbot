{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d1db0c2",
   "metadata": {},
   "source": [
    "# Command Line Chatbot for Google Colab\n",
    "\n",
    "This notebook runs the command-line version of the chatbot in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9afd310",
   "metadata": {},
   "source": [
    "## Step 1: Clone the GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c438216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your GitHub repository\n",
    "!git clone https://github.com/ST-SARAVANAPRIYAN/chatbot.git\n",
    "%cd chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76508b6",
   "metadata": {},
   "source": [
    "## Step 2: Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be995b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q llama-index google-generativeai chromadb python-dotenv spacy transformers torch langchain\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5addebd8",
   "metadata": {},
   "source": [
    "## Step 3: Set up your Gemini API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your Gemini API key\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Securely input your API key\n",
    "GEMINI_API_KEY = getpass('Enter your Gemini API key: ')\n",
    "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
    "\n",
    "# Create .env file with the API key\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(f\"GEMINI_API_KEY={GEMINI_API_KEY}\\n\")\n",
    "    f.write(\"CHROMA_DB_DIRECTORY=./chroma_db\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae2508a",
   "metadata": {},
   "source": [
    "## Step 4: Create sample content (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory and sample content if needed\n",
    "import os\n",
    "\n",
    "# Create data directory\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "\n",
    "# Check if directory is empty\n",
    "if not os.listdir(\"data\"):\n",
    "    print(\"Creating sample FAQ document...\")\n",
    "    \n",
    "    # Create a sample FAQ file\n",
    "    with open(\"data/sample_faq.md\", \"w\") as f:\n",
    "        f.write(\"# Sample FAQ\\n\\n\")\n",
    "        f.write(\"## What is this chatbot?\\n\")\n",
    "        f.write(\"This is a RAG-based chatbot using Google Gemini API.\\n\\n\")\n",
    "        f.write(\"## What is RAG?\\n\")\n",
    "        f.write(\"RAG stands for Retrieval-Augmented Generation, which enhances LLM responses with retrieved information.\\n\\n\")\n",
    "        f.write(\"## How does it work?\\n\")\n",
    "        f.write(\"It uses vector embeddings to find relevant information and then generates responses based on that information.\\n\")\n",
    "    \n",
    "    print(\"Sample content created!\")\n",
    "else:\n",
    "    print(\"Data directory already contains files:\")\n",
    "    for file in os.listdir(\"data\"):\n",
    "        print(f\"- {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7694bf",
   "metadata": {},
   "source": [
    "## Step 5: Install the specific version of LlamaIndex\n",
    "\n",
    "Installing a known compatible version can help avoid import issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d409e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a specific version of LlamaIndex that's known to work well\n",
    "!pip install -q llama-index==0.9.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda544d3",
   "metadata": {},
   "source": [
    "## Step 6: Run the ultra-flexible command-line chatbot\n",
    "\n",
    "This version has enhanced error handling for different LlamaIndex versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51225d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run colab_ultra_flexible.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028be5a",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "If you encounter issues with imports:\n",
    "\n",
    "1. Try running the command below to install a different version of LlamaIndex:\n",
    "```python\n",
    "!pip install -q llama-index==0.8.54\n",
    "```\n",
    "\n",
    "2. Restart the notebook runtime (Runtime > Restart runtime)\n",
    "3. Run the notebook from the beginning"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
